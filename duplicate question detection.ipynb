{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\99896\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer(\"./stsb-distilbert-base-quora-duplicate-questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.0000e+00,  8.7658e-01, -4.5598e-02, -8.0722e-02,  1.1243e-01,\n",
      "          1.9686e-01,  1.1571e-01,  1.4253e-01,  2.3099e-01,  2.2219e-01,\n",
      "         -5.9828e-02, -8.9349e-02,  8.4794e-02,  7.2442e-02, -2.6264e-02,\n",
      "         -1.2309e-02, -1.4192e-02,  1.7120e-02, -1.0189e-01,  5.9221e-01,\n",
      "          5.3040e-01,  8.9872e-02,  6.8932e-02,  1.7726e-01,  1.6068e-01],\n",
      "        [ 8.7658e-01,  1.0000e+00,  3.6747e-02,  2.3680e-02,  1.4728e-01,\n",
      "          2.2269e-01,  2.0482e-01,  2.1311e-01,  2.8756e-01,  2.4903e-01,\n",
      "         -2.4927e-02, -6.5546e-02,  9.5585e-02,  1.3597e-01, -8.3534e-03,\n",
      "          1.0951e-02,  2.1105e-03,  1.4016e-03, -8.6109e-02,  5.6185e-01,\n",
      "          4.8739e-01,  6.5596e-02,  7.8036e-02,  1.3842e-01,  1.3997e-01],\n",
      "        [-4.5598e-02,  3.6747e-02,  1.0000e+00,  6.1158e-01,  1.9979e-01,\n",
      "          1.7288e-01,  1.8189e-01,  1.2918e-01,  1.5837e-01,  1.1906e-01,\n",
      "          3.6659e-01,  2.6083e-01,  2.6515e-02, -4.5575e-02,  2.1987e-01,\n",
      "          2.1809e-01,  3.9817e-02, -6.2870e-02,  5.7686e-02,  1.4438e-01,\n",
      "          1.2594e-01,  1.2353e-01,  2.0166e-02,  3.5783e-02,  1.2305e-01],\n",
      "        [-8.0722e-02,  2.3680e-02,  6.1158e-01,  1.0000e+00,  2.0254e-01,\n",
      "          9.1677e-02,  2.3521e-01,  1.7129e-01,  1.4701e-01,  1.0735e-01,\n",
      "          3.0615e-01,  2.4976e-01, -5.0163e-02, -5.0089e-02,  1.6857e-01,\n",
      "          1.9550e-01, -7.9237e-03, -1.0475e-01, -1.3282e-01,  1.2727e-01,\n",
      "          1.7344e-01,  7.8730e-02,  8.3476e-02,  1.0824e-02,  1.1161e-01],\n",
      "        [ 1.1243e-01,  1.4728e-01,  1.9979e-01,  2.0254e-01,  1.0000e+00,\n",
      "          8.0637e-01,  1.8434e-01,  1.5474e-01,  1.9452e-01,  1.6745e-01,\n",
      "          1.0882e-01,  4.8012e-02, -7.0231e-02, -6.4399e-02,  1.7526e-01,\n",
      "          1.1436e-01,  4.9081e-03, -9.0699e-02, -1.4579e-01,  1.4025e-01,\n",
      "          2.0466e-01,  1.3985e-01,  9.6605e-02,  8.5419e-02,  1.1957e-01],\n",
      "        [ 1.9686e-01,  2.2269e-01,  1.7288e-01,  9.1677e-02,  8.0637e-01,\n",
      "          1.0000e+00,  1.8812e-01,  2.0451e-01,  2.4988e-01,  1.9525e-01,\n",
      "          1.3852e-02,  4.3788e-02, -3.7217e-03,  2.2262e-02,  1.2329e-01,\n",
      "          4.3605e-02,  4.3472e-02, -8.2420e-02, -1.2295e-01,  1.5070e-01,\n",
      "          2.3960e-01,  1.2623e-01,  1.3222e-01,  1.5549e-01,  2.1831e-01],\n",
      "        [ 1.1571e-01,  2.0482e-01,  1.8189e-01,  2.3521e-01,  1.8434e-01,\n",
      "          1.8812e-01,  1.0000e+00,  8.7651e-01, -3.8285e-02, -6.3666e-02,\n",
      "         -1.0010e-01, -9.4575e-02,  3.0019e-02,  9.5744e-02,  1.8215e-01,\n",
      "          1.9104e-01, -1.7615e-02, -1.0172e-01,  7.7925e-02,  1.0591e-01,\n",
      "          1.3833e-01,  2.2346e-01,  2.4922e-01,  2.5541e-01,  2.6696e-01],\n",
      "        [ 1.4253e-01,  2.1311e-01,  1.2918e-01,  1.7129e-01,  1.5474e-01,\n",
      "          2.0451e-01,  8.7651e-01,  1.0000e+00,  2.2906e-02,  9.3460e-03,\n",
      "         -1.1683e-01, -9.0244e-02,  6.6546e-02,  1.8083e-01,  1.6787e-01,\n",
      "          1.5791e-01, -2.3138e-03, -1.1256e-01,  5.6517e-02,  8.6645e-02,\n",
      "          1.3633e-01,  2.0367e-01,  3.0422e-01,  2.7260e-01,  3.4416e-01],\n",
      "        [ 2.3099e-01,  2.8756e-01,  1.5837e-01,  1.4701e-01,  1.9452e-01,\n",
      "          2.4988e-01, -3.8285e-02,  2.2906e-02,  1.0000e+00,  9.0872e-01,\n",
      "          8.8871e-02,  8.0188e-02,  1.2045e-01,  1.2486e-01, -2.4659e-02,\n",
      "         -3.9526e-03,  1.6766e-01,  1.2079e-01, -1.4993e-01,  3.9274e-01,\n",
      "          4.0961e-01,  1.0153e-01,  7.6140e-02,  2.9790e-02,  1.2449e-01],\n",
      "        [ 2.2219e-01,  2.4903e-01,  1.1906e-01,  1.0735e-01,  1.6745e-01,\n",
      "          1.9525e-01, -6.3666e-02,  9.3460e-03,  9.0872e-01,  1.0000e+00,\n",
      "          1.0462e-01,  1.0296e-01,  1.3823e-01,  1.5060e-01, -7.9464e-02,\n",
      "         -5.5168e-02,  1.7466e-01,  1.2947e-01, -8.4715e-02,  3.6472e-01,\n",
      "          3.9547e-01,  9.8813e-03,  1.2742e-02,  8.5099e-02,  1.6428e-01],\n",
      "        [-5.9828e-02, -2.4927e-02,  3.6659e-01,  3.0615e-01,  1.0882e-01,\n",
      "          1.3852e-02, -1.0010e-01, -1.1683e-01,  8.8871e-02,  1.0462e-01,\n",
      "          1.0000e+00,  7.7763e-01,  1.9490e-02,  3.3897e-02,  4.6912e-02,\n",
      "          1.0698e-01, -6.1352e-02,  1.0154e-01, -1.4938e-02,  7.6201e-02,\n",
      "          9.0030e-02,  8.4732e-02,  7.1762e-02,  4.0490e-02,  8.8362e-02],\n",
      "        [-8.9349e-02, -6.5546e-02,  2.6083e-01,  2.4976e-01,  4.8012e-02,\n",
      "          4.3788e-02, -9.4575e-02, -9.0244e-02,  8.0188e-02,  1.0296e-01,\n",
      "          7.7763e-01,  1.0000e+00,  4.5823e-02,  9.3947e-02,  4.1855e-02,\n",
      "          1.0247e-01, -2.1253e-02,  1.3278e-01, -1.3178e-02,  7.9079e-02,\n",
      "          7.0908e-02,  9.1850e-02,  1.3160e-01,  5.2704e-02,  1.0457e-01],\n",
      "        [ 8.4794e-02,  9.5585e-02,  2.6515e-02, -5.0163e-02, -7.0231e-02,\n",
      "         -3.7217e-03,  3.0019e-02,  6.6546e-02,  1.2045e-01,  1.3823e-01,\n",
      "          1.9490e-02,  4.5823e-02,  1.0000e+00,  8.4897e-01,  4.9636e-03,\n",
      "          4.8836e-03, -1.0008e-02, -1.1147e-02,  7.4983e-02,  3.0652e-02,\n",
      "          1.6228e-02, -6.2323e-03, -5.4881e-02,  1.4037e-01,  1.3905e-01],\n",
      "        [ 7.2442e-02,  1.3597e-01, -4.5575e-02, -5.0089e-02, -6.4399e-02,\n",
      "          2.2262e-02,  9.5744e-02,  1.8083e-01,  1.2486e-01,  1.5060e-01,\n",
      "          3.3897e-02,  9.3947e-02,  8.4897e-01,  1.0000e+00,  2.3567e-02,\n",
      "          5.9892e-02,  8.1666e-03, -3.1525e-02,  4.1881e-02,  2.3586e-02,\n",
      "          6.8873e-03, -2.0140e-02,  5.4432e-02,  1.1352e-01,  1.8057e-01],\n",
      "        [-2.6264e-02, -8.3534e-03,  2.1987e-01,  1.6857e-01,  1.7526e-01,\n",
      "          1.2329e-01,  1.8215e-01,  1.6787e-01, -2.4659e-02, -7.9464e-02,\n",
      "          4.6912e-02,  4.1855e-02,  4.9636e-03,  2.3567e-02,  1.0000e+00,\n",
      "          9.2025e-01,  3.8970e-02,  6.4989e-02, -8.6830e-02,  9.1722e-02,\n",
      "          2.7324e-02,  9.8747e-02,  1.3373e-01,  3.5635e-02,  1.2092e-01],\n",
      "        [-1.2309e-02,  1.0951e-02,  2.1809e-01,  1.9550e-01,  1.1436e-01,\n",
      "          4.3605e-02,  1.9104e-01,  1.5791e-01, -3.9526e-03, -5.5168e-02,\n",
      "          1.0698e-01,  1.0247e-01,  4.8836e-03,  5.9892e-02,  9.2025e-01,\n",
      "          1.0000e+00,  2.5452e-02,  7.7262e-02, -8.8106e-02,  1.0787e-01,\n",
      "          2.1781e-02,  1.1911e-01,  1.4162e-01,  2.3749e-02,  1.2298e-01],\n",
      "        [-1.4192e-02,  2.1105e-03,  3.9817e-02, -7.9237e-03,  4.9081e-03,\n",
      "          4.3472e-02, -1.7615e-02, -2.3138e-03,  1.6766e-01,  1.7466e-01,\n",
      "         -6.1352e-02, -2.1253e-02, -1.0008e-02,  8.1666e-03,  3.8970e-02,\n",
      "          2.5452e-02,  1.0000e+00,  4.5440e-01,  1.9104e-01,  1.3744e-01,\n",
      "          9.1939e-02, -1.9431e-02,  1.7434e-02,  5.4217e-02,  6.2192e-02],\n",
      "        [ 1.7120e-02,  1.4016e-03, -6.2870e-02, -1.0475e-01, -9.0699e-02,\n",
      "         -8.2420e-02, -1.0172e-01, -1.1256e-01,  1.2079e-01,  1.2947e-01,\n",
      "          1.0154e-01,  1.3278e-01, -1.1147e-02, -3.1525e-02,  6.4989e-02,\n",
      "          7.7262e-02,  4.5440e-01,  1.0000e+00,  9.1422e-02,  6.3200e-02,\n",
      "         -1.7211e-03,  2.8311e-02,  7.5459e-04,  1.6616e-01,  1.2342e-01],\n",
      "        [-1.0189e-01, -8.6109e-02,  5.7686e-02, -1.3282e-01, -1.4579e-01,\n",
      "         -1.2295e-01,  7.7925e-02,  5.6517e-02, -1.4993e-01, -8.4715e-02,\n",
      "         -1.4938e-02, -1.3178e-02,  7.4983e-02,  4.1881e-02, -8.6830e-02,\n",
      "         -8.8106e-02,  1.9104e-01,  9.1422e-02,  1.0000e+00, -2.6994e-02,\n",
      "         -9.8273e-02, -1.1760e-02, -1.9289e-02,  3.1507e-02, -6.4773e-02],\n",
      "        [ 5.9221e-01,  5.6185e-01,  1.4438e-01,  1.2727e-01,  1.4025e-01,\n",
      "          1.5070e-01,  1.0591e-01,  8.6645e-02,  3.9274e-01,  3.6472e-01,\n",
      "          7.6201e-02,  7.9079e-02,  3.0652e-02,  2.3586e-02,  9.1722e-02,\n",
      "          1.0787e-01,  1.3744e-01,  6.3200e-02, -2.6994e-02,  1.0000e+00,\n",
      "          7.6263e-01,  1.1325e-01,  1.2831e-01,  4.3770e-02,  7.0696e-02],\n",
      "        [ 5.3040e-01,  4.8739e-01,  1.2594e-01,  1.7344e-01,  2.0466e-01,\n",
      "          2.3960e-01,  1.3833e-01,  1.3633e-01,  4.0961e-01,  3.9547e-01,\n",
      "          9.0030e-02,  7.0908e-02,  1.6228e-02,  6.8873e-03,  2.7324e-02,\n",
      "          2.1781e-02,  9.1939e-02, -1.7211e-03, -9.8273e-02,  7.6263e-01,\n",
      "          1.0000e+00,  1.3998e-01,  1.8242e-01,  1.2047e-01,  1.6847e-01],\n",
      "        [ 8.9872e-02,  6.5596e-02,  1.2353e-01,  7.8730e-02,  1.3985e-01,\n",
      "          1.2623e-01,  2.2346e-01,  2.0367e-01,  1.0153e-01,  9.8813e-03,\n",
      "          8.4732e-02,  9.1850e-02, -6.2323e-03, -2.0140e-02,  9.8747e-02,\n",
      "          1.1911e-01, -1.9431e-02,  2.8311e-02, -1.1760e-02,  1.1325e-01,\n",
      "          1.3998e-01,  1.0000e+00,  8.2206e-01,  5.7557e-02,  1.1385e-01],\n",
      "        [ 6.8932e-02,  7.8036e-02,  2.0166e-02,  8.3476e-02,  9.6605e-02,\n",
      "          1.3222e-01,  2.4922e-01,  3.0422e-01,  7.6140e-02,  1.2742e-02,\n",
      "          7.1762e-02,  1.3160e-01, -5.4881e-02,  5.4432e-02,  1.3373e-01,\n",
      "          1.4162e-01,  1.7434e-02,  7.5459e-04, -1.9289e-02,  1.2831e-01,\n",
      "          1.8242e-01,  8.2206e-01,  1.0000e+00,  1.0722e-01,  2.0246e-01],\n",
      "        [ 1.7726e-01,  1.3842e-01,  3.5783e-02,  1.0824e-02,  8.5419e-02,\n",
      "          1.5549e-01,  2.5541e-01,  2.7260e-01,  2.9790e-02,  8.5099e-02,\n",
      "          4.0490e-02,  5.2704e-02,  1.4037e-01,  1.1352e-01,  3.5635e-02,\n",
      "          2.3749e-02,  5.4217e-02,  1.6616e-01,  3.1507e-02,  4.3770e-02,\n",
      "          1.2047e-01,  5.7557e-02,  1.0722e-01,  1.0000e+00,  7.9136e-01],\n",
      "        [ 1.6068e-01,  1.3997e-01,  1.2305e-01,  1.1161e-01,  1.1957e-01,\n",
      "          2.1831e-01,  2.6696e-01,  3.4416e-01,  1.2449e-01,  1.6428e-01,\n",
      "          8.8362e-02,  1.0457e-01,  1.3905e-01,  1.8057e-01,  1.2092e-01,\n",
      "          1.2298e-01,  6.2192e-02,  1.2342e-01, -6.4773e-02,  7.0696e-02,\n",
      "          1.6847e-01,  1.1385e-01,  2.0246e-01,  7.9136e-01,  1.0000e+00]])\n",
      " 1: How does chocolate get made?\n",
      " 1: What is the best way to learn Python?\n",
      " 1: What are the steps involved in machine learning?\n",
      " 1: How do I make pasta?\n",
      " 1: What is the best book for AFCAT preparation?\n",
      " 1: How does a car engine work?\n",
      " 1: How to improve public speaking skills?\n",
      " 1: How to bake a cake?\n",
      " 1: How does a blockchain work?\n",
      " 1: What is artificial intelligence?\n",
      " 2: How do you prepare for exams effectively?\n",
      " 2: What are some effective study methods for exams?\n",
      " 2: What is the capital of France?\n",
      " 2: Where is the Eiffel Tower located?\n",
      " 2: What is the time now?\n",
      "[[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentences = [\n",
    "   \"How does chocolate get made?\",\n",
    "    \"What is the process of making chocolate?\",\n",
    "    \"How do you prepare for exams effectively?\",\n",
    "    \"What are some effective study methods for exams?\",\n",
    "    \"What is the best way to learn Python?\",\n",
    "    \"How can I start learning Python?\",\n",
    "    \"What are the steps involved in machine learning?\",\n",
    "    \"Explain the process of machine learning.\",\n",
    "    \"How do I make pasta?\",\n",
    "    \"Can you tell me how pasta is made?\",\n",
    "    \"What is the best book for AFCAT preparation?\",\n",
    "    \"Can you suggest some books for AFCAT?\",\n",
    "    \"How does a car engine work?\",\n",
    "    \"Explain the working principle of a car engine.\",\n",
    "    \"How to improve public speaking skills?\",\n",
    "    \"What are some tips for improving public speaking?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Where is the Eiffel Tower located?\",\n",
    "    \"What is the time now?\",\n",
    "    \"How to bake a cake?\",\n",
    "    \"Can you give me a cake recipe?\",\n",
    "    \"How does a blockchain work?\",\n",
    "    \"Explain blockchain technology.\",\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"Define artificial intelligence in simple terms.\"\n",
    "]\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "\n",
    "# Convert the similarities to binary similarities\n",
    "similarities=similarities.numpy()\n",
    "printed=[]\n",
    "binary_similarities = (similarities > 0.75).astype(int)\n",
    "for i in range(len(similarities)):\n",
    "    for j in range(len(similarities)):\n",
    "        if i != j and binary_similarities[i][j] ==1 and i not in printed:\n",
    "            printed.append(i)\n",
    "            printed.append(j)\n",
    "            print(\" 1:\", sentences[i])\n",
    "for i in range(len(similarities)):\n",
    "    if i not in printed:\n",
    "        print(\" 2:\", sentences[i])\n",
    "\n",
    "print(binary_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9536\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "true_labels = [\n",
    "    [0, 1],  # \"How does chocolate get made?\" and \"What is the process of making chocolate?\"\n",
    "    [2, 3],  # Exam preparation questions\n",
    "    [4, 5],  # Python learning questions\n",
    "    [6, 7],  # Machine learning questions\n",
    "    [8, 9],  # Pasta making questions\n",
    "    [10, 11], # AFCAT book suggestions\n",
    "    [12, 13], # Car engine questions\n",
    "    [14, 15], # Public speaking questions\n",
    "    [16, 17], # France and Eiffel Tower\n",
    "    [18],     # \"What is the time now?\" is unique\n",
    "    [19, 20], # Cake recipe questions\n",
    "    [21, 22], # Blockchain questions\n",
    "    [23, 24]  # AI questions\n",
    "]\n",
    "\n",
    "# Flatten the true_labels to create a list of true binary relations (True or False)\n",
    "true_binary = np.zeros_like(binary_similarities, dtype=int)\n",
    "for cluster in true_labels:\n",
    "    for i in cluster:\n",
    "        for j in cluster:\n",
    "            if i != j:\n",
    "                true_binary[i][j] = 1\n",
    "\n",
    "# Calculate the accuracy by comparing the binary similarity matrix with the ground truth\n",
    "accuracy = accuracy_score(true_binary.flatten(), binary_similarities.flatten())\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  6 14  9  8  8  4  4  5  5  1  1  2  2 11 11 12 10 13  0  0  7  7  3\n",
      "  3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "sentences = [\n",
    "    \"How does chocolate get made?\",\n",
    "    \"What is the process of making chocolate?\",\n",
    "    \"How do you prepare for exams effectively?\",\n",
    "    \"What are some effective study methods for exams?\",\n",
    "    \"What is the best way to learn Python?\",\n",
    "    \"How can I start learning Python?\",\n",
    "    \"What are the steps involved in machine learning?\",\n",
    "    \"Explain the process of machine learning.\",\n",
    "    \"How do I make pasta?\",\n",
    "    \"Can you tell me how pasta is made?\",\n",
    "    \"What is the best book for AFCAT preparation?\",\n",
    "    \"Can you suggest some books for AFCAT?\",\n",
    "    \"How does a car engine work?\",\n",
    "    \"Explain the working principle of a car engine.\",\n",
    "    \"How to improve public speaking skills?\",\n",
    "    \"What are some tips for improving public speaking?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Where is the Eiffel Tower located?\",\n",
    "    \"What is the time now?\",\n",
    "    \"How to bake a cake?\",\n",
    "    \"Can you give me a cake recipe?\",\n",
    "    \"How does a blockchain work?\",\n",
    "    \"Explain blockchain technology.\",\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"Define artificial intelligence in simple terms.\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "similarities=similarities.numpy()\n",
    "clustering = AgglomerativeClustering(n_clusters=None, metric='precomputed', linkage='average', distance_threshold=0.25)\n",
    "labels = clustering.fit_predict(1 - similarities)\n",
    "print(labels)\n",
    "# Step 5: Find the most representative question for each cluster\n",
    "unique_questions = []\n",
    "\n",
    "for label in np.unique(labels):\n",
    "    cluster_indices = np.where(labels == label)[0]\n",
    "    \n",
    "    # Step 5.1: Calculate centroid of the cluster\n",
    "    cluster_embeddings = embeddings[cluster_indices]\n",
    "    centroid = np.mean(cluster_embeddings, axis=0)\n",
    "    \n",
    "    # Step 5.2: Find the question closest to the centroid\n",
    "    similarities_to_centroid = cosine_similarity([centroid], cluster_embeddings)[0]\n",
    "    closest_question_idx = np.argmax(similarities_to_centroid)\n",
    "    unique_questions.append(sentences[cluster_indices[closest_question_idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of questions: 25\n",
      "Number of unique questions after clustering: 15\n",
      "Unique questions:\n",
      "['How to bake a cake?', 'What is the best book for AFCAT preparation?', 'How does a car engine work?', 'What is artificial intelligence?', 'Explain the process of machine learning.', 'How do I make pasta?', 'What is the process of making chocolate?', 'How does a blockchain work?', 'How can I start learning Python?', 'What are some effective study methods for exams?', 'Where is the Eiffel Tower located?', 'How to improve public speaking skills?', 'What is the capital of France?', 'What is the time now?', 'How do you prepare for exams effectively?']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original number of questions: {len(sentences)}\")\n",
    "print(f\"Number of unique questions after clustering: {len(unique_questions)}\")\n",
    "print(\"Unique questions:\")\n",
    "print(unique_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
